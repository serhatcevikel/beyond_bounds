{"metadata":{"kernelspec":{"display_name":"R","language":"R","name":"ir"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.2.1"},"toc-autonumbering":true},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<font size=\"6\"><b>RECURSIVE PARTIONING TREE TOY EXAMPLE</b></font>","metadata":{},"id":"0dca0857-3f2a-49e0-b62b-cd0682ace5fb"},{"cell_type":"code","source":"library(tidyverse)\nlibrary(data.table)\nlibrary(MASS) # for generating random samples from multivariate normal distribution\nlibrary(trialr) # for generating random correlation matrix from LKJ distribution\nlibrary(rpart) # for recursive partioning trees\nlibrary(visNetwork) # for better plotting recursive partioning trees","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"af46a7a3-3fc4-48f9-9d4c-c73d0cc81a1b"},{"cell_type":"code","source":"options(repr.matrix.max.rows=20, repr.matrix.max.cols=15) # for limiting the number of top and bottom rows of tables printed ","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"d0713512-973f-4d18-ac83-73fb5123db07"},{"cell_type":"markdown","source":"We will simulate a toy dataset to demonstrate decision tree algorithm for classification:","metadata":{},"id":"4b68ab93-4d2c-4d60-a363-0c5dab0e1dfb"},{"cell_type":"markdown","source":"We will sample continous values from multivariate normal distribution and then discretize them to get factor variables:","metadata":{},"id":"32d6cb72-973e-4934-aa42-8fb3c1ff5103"},{"cell_type":"markdown","source":"# Data generation and preparation","metadata":{},"id":"c76b4528-91a5-416f-89c1-2b9a4bbfce0c"},{"cell_type":"markdown","source":"Let's first create a random correlation matrix using the relevant LKJ distribution:","metadata":{},"id":"ef4ed749-30ea-43a1-81a5-9653103a2328"},{"cell_type":"code","source":"set.seed(1)\nmatcor <- rlkjcorr(1, 3, 0.1)","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"9869daba-2c04-4f41-adfc-d234d70cc095"},{"cell_type":"code","source":"matcor","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"87382fec-bba1-480d-8a58-96bafeee0016"},{"cell_type":"markdown","source":"And let's sample some correlated random values from multivariate normal distribution:","metadata":{},"id":"eec97258-20e5-4442-b275-bf52c18264cc"},{"cell_type":"code","source":"set.seed(1)\nvals <- mvrnorm(2e2, rep(0, 3), matcor)","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"4b14490a-b046-44b4-83ba-7abd0aed19d1"},{"cell_type":"code","source":"vals","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"015cbf45-0f89-4c80-953c-ce8d66bf2351"},{"cell_type":"markdown","source":"Check the correlation matrix of sampled values:","metadata":{},"id":"8db57487-7b87-4382-8bc2-5999e6726fbe"},{"cell_type":"code","source":"cor(vals)","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"41f412f9-97cb-4645-b1b4-0034734171aa"},{"cell_type":"markdown","source":"Similar to the generating correlation matrix we passed","metadata":{},"id":"d31c43e8-e138-41c3-b794-c75f352a3f44"},{"cell_type":"markdown","source":"Make it a data.table:","metadata":{},"id":"318f6760-24d5-435f-8622-0ba0a0d1d147"},{"cell_type":"code","source":"vals_dt <- as.data.table(vals)","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"4a510e0c-34ff-492b-b7f2-f3f2859f1a95"},{"cell_type":"markdown","source":"First column will be the response variable, others are independent variables:","metadata":{},"id":"3ce74362-73c0-4b3e-84b2-37477661948c"},{"cell_type":"code","source":"setnames(vals_dt, c(\"dep\", \"ind1\", \"ind2\"))","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"41c16d55-7de6-4b19-bd19-117bbc626e10"},{"cell_type":"markdown","source":"Discretize values:","metadata":{},"id":"cdc81828-78bc-467a-840e-aea8b447276a"},{"cell_type":"code","source":"vals_dt <- vals_dt %>% mutate_all(cut, c(-Inf, 0, Inf), c(\"no\", \"yes\"))","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"3306ac9f-d420-42f8-84c1-9bd85899f8d7"},{"cell_type":"markdown","source":"Check the correlation among classes:","metadata":{},"id":"44988b53-2cbc-43c5-b4e0-11638b36d628"},{"cell_type":"code","source":"cor(vals_dt %>% mutate_all(as.integer))","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"bc2dfc92-2e55-44cb-85df-3e1b0254c79a"},{"cell_type":"markdown","source":"Let's visualize the possible splits:","metadata":{},"id":"1ac6e186-1e86-45c6-ab0e-d4d66a635728"},{"cell_type":"code","source":"vals_dt %>%\nmutate_at(c(\"ind1\", \"ind2\"), as.integer) %>%\nggplot(aes(x = ind1, y = ind2, col = dep)) +\ngeom_jitter() +\ngeom_hline(yintercept = 1.5) +\ngeom_vline(xintercept = 1.5)","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"05414151-86d1-4483-bb63-7b9ddef7da35"},{"cell_type":"markdown","source":"# Entropy/impurity","metadata":{},"id":"6e2643dc-fdf4-4b2c-b61d-d3805dd7f333"},{"cell_type":"markdown","source":"Let's formalize this through entropy measure:","metadata":{},"id":"6f2ba04e-7091-49f0-9e79-0f1f937177a7"},{"cell_type":"markdown","source":"$${\\displaystyle \\mathrm {H} (X):=-\\sum _{x\\in {\\mathcal {X}}}p(x)\\log p(x),}$$\n\n(https://en.wikipedia.org/wiki/Entropy_(information_theory))","metadata":{},"id":"03bca7ff-e583-4476-a498-dfe6969f5966"},{"cell_type":"code","source":"ps <- 0.5","metadata":{"trusted":true,"tags":[]},"execution_count":null,"outputs":[],"id":"e7758b26-ccb6-4453-b392-b5e3d6858648"},{"cell_type":"code","source":"props <- c(ps, 1 - ps)","metadata":{"trusted":true,"tags":[]},"execution_count":null,"outputs":[],"id":"fdb9f20a-0aac-43cd-ba78-a2dfffe41f26"},{"cell_type":"code","source":"sum(-props * log2(props))","metadata":{"trusted":true,"tags":[]},"execution_count":null,"outputs":[],"id":"e73a129c-fb74-4a7c-ac89-1ef5174c4c0c"},{"cell_type":"code","source":"entrop <- function(x)\n{\n    props <- prop.table(table(as.character(x)))\n    sum(-props * log2(props))\n}","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"9c74cdee-feb7-4be4-8166-e7b5e44a3af1"},{"cell_type":"markdown","source":"And the gini impurity measure:","metadata":{},"id":"97d715bc-dbbb-430d-82c9-8a4bc9eb4644"},{"cell_type":"markdown","source":"$${\\displaystyle \\operatorname {I} _{G}(p)=1-\\sum _{i=1}^{J}p_{i}^{2}.}$$\n\n(https://en.wikipedia.org/wiki/Decision_tree_learning#Gini_impurity)","metadata":{},"id":"740f2c4b-25ae-4823-ba75-08d1f746807b"},{"cell_type":"code","source":"ginix <- function(x)\n{\n    props <- prop.table(table(as.character(x)))\n    1- sum(props^2)\n}","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"ec97d36e-77d7-4865-ad50-b293941f5eaa"},{"cell_type":"markdown","source":"Now let's make a digression to understand entropy.","metadata":{},"id":"f4d262d9-fcc2-48c9-bd8d-c62384b25026"},{"cell_type":"markdown","source":"For two class case, entropy value for different percentages of a case is:","metadata":{},"id":"cfff33e1-def6-4475-b744-14f952671624"},{"cell_type":"code","source":"ps <- seq(0, 1, 0.1) %>% pmax(1e-22) %>% pmin(1-(1e-16))\nps","metadata":{"trusted":true,"tags":[]},"execution_count":null,"outputs":[],"id":"fed38f34-9add-4567-86da-d53414d54b8a"},{"cell_type":"code","source":"psdt <- data.table(ps)","metadata":{"trusted":true,"tags":[]},"execution_count":null,"outputs":[],"id":"9d3d0fee-8e74-4365-a627-7b70ddf9c555"},{"cell_type":"code","source":"psdt[, ent := sapply(ps, function(x) -sum(c(x, 1-x) * log2(c(x, 1-x))))]","metadata":{"trusted":true,"tags":[]},"execution_count":null,"outputs":[],"id":"12e47873-e8b9-4f13-b971-4f91d59aa211"},{"cell_type":"code","source":"psdt","metadata":{"trusted":true,"tags":[]},"execution_count":null,"outputs":[],"id":"b9ef731e-abc4-434d-892f-1390e5d7125f"},{"cell_type":"code","source":"psdt %>%\nggplot(aes(x = ps, y = ent)) +\ngeom_line()","metadata":{"trusted":true,"tags":[]},"execution_count":null,"outputs":[],"id":"9cd47133-bdeb-41ef-bdd2-7ec4cfe28be1"},{"cell_type":"markdown","source":"The entropy is at a maximum at ps = 0.5, so we have equal share of cases. What does that mean?\n\nOne interpretation of entropy is uncertainty, disorderliness or impurity.\n\nBut why?","metadata":{},"id":"799dd72d-b278-400c-af4b-043bdeeadcf9"},{"cell_type":"markdown","source":"Let's assume we toss a fair coin 10 times and calculate the counts of heads we get.\n\nWhat are the probabilities of getting each count?","metadata":{},"id":"2415d93e-084f-43eb-80ad-5dfd1e0d687a"},{"cell_type":"code","source":"data.table(count = 0:10, prob = dbinom(0:10, 10, 0.5)) %>%\nggplot(aes(x = count, y = prob)) +\ngeom_line()","metadata":{"trusted":true,"tags":[]},"execution_count":null,"outputs":[],"id":"af1451ee-d1c9-4fd9-9db9-d81daca6b9df"},{"cell_type":"markdown","source":"A very similar figure.","metadata":{},"id":"384be5dd-b597-4176-b6fb-7e27105c3bc9"},{"cell_type":"markdown","source":"What is the probability of getting a certain sequence of head or tail values for each count of heads?","metadata":{},"id":"dcc5771e-6dc9-4b47-88d2-02ed8c52f43f"},{"cell_type":"code","source":"0.5^(0:10) * 0.5^(10:0)","metadata":{"trusted":true,"tags":[]},"execution_count":null,"outputs":[],"id":"bfdddd29-8339-4895-9746-2964b30eb99f"},{"cell_type":"markdown","source":"Because of the symmetric probabilities of each side, all sequences or configurations have the same probability","metadata":{},"id":"da74d6b2-b1f5-42e9-995a-a2308bb31031"},{"cell_type":"markdown","source":"How many configurations we may have? Size of power set","metadata":{},"id":"91ea6c70-dcdb-4775-956d-576489446260"},{"cell_type":"code","source":"2^10","metadata":{"trusted":true,"tags":[]},"execution_count":null,"outputs":[],"id":"e5ff4b27-9b78-4547-b350-0c66ad145c8d"},{"cell_type":"markdown","source":"Total probability is:","metadata":{},"id":"82aa2dfc-c1a7-43fe-bdd6-cd08bfa7488a"},{"cell_type":"code","source":"0.5^10 * 2^10","metadata":{"trusted":true,"tags":[]},"execution_count":null,"outputs":[],"id":"882f5610-b671-4bdf-b456-19a485189dd5"},{"cell_type":"markdown","source":"Quite obvious:\n\n$$(0.5 * 2)^{10} = 1^{10} = 1$$","metadata":{},"id":"1d6ca7f3-156c-4cc7-88ed-468c1fb7d20e"},{"cell_type":"markdown","source":"Now have many configurations or sequences yield each of the head counts?","metadata":{},"id":"f4ac2a42-70cd-45e5-b8ad-e1887f8ff947"},{"cell_type":"code","source":"choose(10, 0:10)","metadata":{"trusted":true,"tags":[]},"execution_count":null,"outputs":[],"id":"b0c7786b-c0ca-4ceb-adbd-03d9b491dbb3"},{"cell_type":"markdown","source":"Or:","metadata":{},"id":"0c8ce30a-abd3-4db9-b5e3-5c61dc99aa34"},{"cell_type":"code","source":"factorial(10) / (factorial(10 - 0:10) * factorial(0:10))","metadata":{"trusted":true,"tags":[]},"execution_count":null,"outputs":[],"id":"04d2d8d5-7dff-40aa-a16e-b38aaeaaa61e"},{"cell_type":"markdown","source":"And let's multiply this number of different ways to get a certain count and the probabilities of each configuration:","metadata":{},"id":"8fd36d21-f600-4ac1-9ae9-f0f5c31c5ea5"},{"cell_type":"code","source":"data.table(count = 0:10, prob = choose(10, 0:10) * 0.5^(0:10) * 0.5^(10:0)) %>%\nggplot(aes(x = count, y = prob)) +\ngeom_line()","metadata":{"trusted":true,"tags":[]},"execution_count":null,"outputs":[],"id":"80cd9e22-f4e3-4640-ba45-92d9d5d7417d"},{"cell_type":"markdown","source":"That's the same figure we get from dbinom, because we used the same formulation for dbinom:","metadata":{},"id":"4f5f30a9-c3c1-4045-aa48-f40df1b31236"},{"cell_type":"markdown","source":"$${\\displaystyle f(k,n,p)=\\Pr(X=k)={\\binom {n}{k}}p^{k}(1-p)^{n-k}}$$\n\n(https://en.wikipedia.org/wiki/Binomial_distribution)","metadata":{},"id":"5b3e6f14-547e-4a36-bfce-a9f02bba1766"},{"cell_type":"markdown","source":"Basically we have a higher probability to get values near the middle in this distribution because **we have more ways - or combinations - to get those count of head values**.\n\nProbability is basically number of ways of counting things.","metadata":{},"id":"14d07106-a6ae-45e5-907f-39724d0f38a4"},{"cell_type":"markdown","source":"# Partitioning","metadata":{},"id":"b5f63c16-fbf2-4b75-86ff-b894945f78d0"},{"cell_type":"markdown","source":"Select the independent variables to split across:","metadata":{},"id":"cd16c98d-6be3-48d9-9310-3313d068abe0"},{"cell_type":"code","source":"vars <- c(\"ind1\", \"ind2\")","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"6a2e58fa-20ee-4c5b-99b2-06c38cc27e77"},{"cell_type":"markdown","source":"See the weighted entropies across two variables:","metadata":{},"id":"188d1e46-a728-4c38-8b66-c2e0912bf55e"},{"cell_type":"code","source":"ents <- sapply(vars, function(x) vals_dt[, .(N = .N, en = entrop(dep)), by = get(x)][, sum(N * en)/sum(N)])","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"28e22cfd-ed19-4d35-a101-ee2bd0a0992c"},{"cell_type":"code","source":"ents","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"6a421b1b-7c31-4773-a274-2f0a751cdcce"},{"cell_type":"markdown","source":"Recalculate using gini impurity values:","metadata":{},"id":"48bf60fb-e38f-4afd-96c8-e77fec231f9a"},{"cell_type":"code","source":"ginis <- sapply(vars, function(x) vals_dt[, .(N = .N, en = ginix(dep)), by = get(x)][, sum(N * en)/sum(N)])","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"ea65baa8-e45a-4d54-8497-b64a83d5e5bb"},{"cell_type":"code","source":"ginis","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"a1fdab8a-0af0-4522-89c1-3c5fa8b5332c"},{"cell_type":"markdown","source":"They are parallel","metadata":{},"id":"9aa8eda1-5ac6-4b09-af5d-1cb6022b03a6"},{"cell_type":"markdown","source":"Select the variable that cause the lower entropy:","metadata":{},"id":"72c4c6be-a528-4293-a8c3-af3e198808f1"},{"cell_type":"code","source":"splitvar1 <- names(ents[which.min(ents)])\nsplitvar1","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"b6ba3f2a-5a70-436d-a1f5-e576de3e84c7"},{"cell_type":"markdown","source":"Split the data.table across this variable:","metadata":{},"id":"3e758d28-066c-4186-9208-8d0d883b7e4a"},{"cell_type":"code","source":"vals_dt_l1 <- split(vals_dt, f = vals_dt[, .(get(splitvar1))])[c(\"no\", \"yes\")]","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"b32afffe-ed09-4db6-a5cf-c2a48d0aaaa8"},{"cell_type":"markdown","source":"And repeat the entropy calculation for both splits across the other variable (there is only one variable left, anyway, nothing to compare):","metadata":{},"id":"824bc070-3dcf-4cd3-9a1c-f48a0d67b054"},{"cell_type":"code","source":"lapply(vals_dt_l1, function(y)\n    {\n    sapply(setdiff(vars, splitvar1), function(x) y[, .(N = .N, en = entrop(dep)), by = get(x)][, sum(N * en)/sum(N)])\n    }\n)","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"311e986d-d997-4154-8dea-6b3db6b8a8ab"},{"cell_type":"markdown","source":"Now let's see the information gain, the reduction in entropy, at the beginning and after each split:","metadata":{},"id":"3e1d2f1a-071b-4be1-94c4-aa7a55df2c6a"},{"cell_type":"markdown","source":"First at the root:","metadata":{},"id":"78debcbe-e0b0-43b9-9c9a-b6079c00b030"},{"cell_type":"code","source":"counts_dt0 <- vals_dt[, .N, by = c(\"dep\")][, prop := N / sum(N)][]","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"8c779f32-a268-4bb1-86ff-a12b2a9f4885"},{"cell_type":"code","source":"counts_dt0","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"e3ad9ef1-97a3-43a4-9b5b-1b4593d63b13"},{"cell_type":"markdown","source":"Get the entropy:","metadata":{},"id":"1f0476b6-4cff-4834-b799-650a9755891e"},{"cell_type":"code","source":"ent0 <- counts_dt0[, sum(-setdiff(prop, 0) * log2(setdiff(prop, 0)))]\nent0","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"68d73463-a4ad-4850-9bb6-0c9f0276680e"},{"cell_type":"markdown","source":"And the error rate:","metadata":{},"id":"da17e407-04f8-4777-9bb5-719152b570ca"},{"cell_type":"code","source":"er0 <- counts_dt0[, sum((N != max(N))*N) / sum(N)]\ner0","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"3dc219d7-b85b-4d34-8aa7-5082b8312703"},{"cell_type":"markdown","source":"Now, after the first split:","metadata":{},"id":"7b02bb67-e0c9-49ef-8197-b38c44c22e58"},{"cell_type":"code","source":"counts_dt1 <- vals_dt[, .N, by = c(\"dep\", splitvar1)][, prop := N / sum(N), by = splitvar1][]","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"9b7ae203-6229-40f7-990e-61d1930252df"},{"cell_type":"code","source":"counts_dt1","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"09371911-9e91-4b8f-b40a-0837042abf08"},{"cell_type":"markdown","source":"The entropy value:","metadata":{},"id":"b5ab4d02-e110-4e4c-9756-753c66833954"},{"cell_type":"code","source":"ent1 <- counts_dt1[, .(N = sum(N), ent = sum(-setdiff(prop, 0) * log2(setdiff(prop, 0)))), by = splitvar1][, sum(N * ent) / sum(N)]\nent1","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"92f89638-a86a-4fdb-b5a2-5d64d5b3ba54"},{"cell_type":"markdown","source":"Entropy is reduced by:","metadata":{},"id":"61c30cf1-4032-4899-aa65-54711c62057e"},{"cell_type":"code","source":"ent0 - ent1","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"7b105cd7-8244-4d96-9a87-4b130f0d4673"},{"cell_type":"markdown","source":"The error rate:","metadata":{},"id":"05e7e153-9502-4948-822c-e8eb742c1459"},{"cell_type":"code","source":"er1 <- counts_dt1[, sum((dep != ind1) * N) / sum(N)]\ner1","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"11839519-340b-4c8d-82cc-a51215e1f529"},{"cell_type":"markdown","source":"And relative decrease in error:","metadata":{},"id":"0e1b738e-f50b-4063-b095-069ad3a2f256"},{"cell_type":"code","source":"1 - er1 / er0","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"4bba34b4-34db-4bb0-8705-b50e88df680e"},{"cell_type":"markdown","source":"Keep that value in mind!","metadata":{},"id":"9418106d-2272-4850-b9e5-2d917b5c9e23"},{"cell_type":"markdown","source":"Now the second split:","metadata":{},"id":"d43fa731-e782-4f32-be31-e1d3ad8d4a0f"},{"cell_type":"code","source":"counts_dt2 <- vals_dt[, .N, by = c(\"dep\", vars)][, prop := N / sum(N), by = vars][]","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"e9565678-8a6a-47b9-99e0-da7e4f1d4027"},{"cell_type":"code","source":"counts_dt2","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"4255dd2b-9b3e-4069-ae5f-114d803f8e8e"},{"cell_type":"markdown","source":"Let's look at the error rate for each split:","metadata":{},"id":"a27430b0-d3bd-4ab6-8e65-0859c1875bc0"},{"cell_type":"markdown","source":"When ind1 == \"yes\" condition is not split further: (labels for the splitting variable are determined such that classification error is minimized)","metadata":{},"id":"fe389b31-9183-40bd-9adb-00fdf9d3f5e9"},{"cell_type":"code","source":"min(\ncounts_dt2[ind1 == \"yes\"][, sum((dep == ind1) * N) / sum(N)],\ncounts_dt2[ind1 == \"yes\"][, sum((dep != ind1) * N) / sum(N)])","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"c32da403-ff47-4e74-89ed-86d393896182"},{"cell_type":"markdown","source":"And when the node is split further by ind2:","metadata":{},"id":"c588204e-6ad1-4a8a-8094-af598367618e"},{"cell_type":"code","source":"min(\ncounts_dt2[ind1 == \"yes\"][, sum((dep == ind2) * N) / sum(N)],\ncounts_dt2[ind1 == \"yes\"][, sum((dep != ind2) * N) / sum(N)])","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"2f358ffb-199c-4693-8d38-f2f840660707"},{"cell_type":"markdown","source":"So the error rate increases with further split on the second variable for the ind1 == \"yes\" split","metadata":{},"id":"537b8606-247d-4462-8670-69e53a5a7e94"},{"cell_type":"markdown","source":"Now let's repeat it for ind1 == \"no\" split","metadata":{},"id":"c49f0cea-6491-4711-9c7f-f0709a9fafc5"},{"cell_type":"code","source":"min(\ncounts_dt2[ind1 == \"no\"][, sum((dep == ind1) * N) / sum(N)],\ncounts_dt2[ind1 == \"no\"][, sum((dep != ind1) * N) / sum(N)])","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"8a386f68-0368-4b05-9738-295e933368ab"},{"cell_type":"markdown","source":"And when the node is split further by ind2:","metadata":{},"id":"4394beeb-9109-4c8a-8928-e1b8504a79bd"},{"cell_type":"code","source":"min(\ncounts_dt2[ind1 == \"no\"][, sum((dep == ind2) * N) / sum(N)],\ncounts_dt2[ind1 == \"no\"][, sum((dep != ind2) * N) / sum(N)])","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"8b3a863f-d62b-44cb-82ca-361da472dc09"},{"cell_type":"markdown","source":"The error rate decreases for that split","metadata":{},"id":"e8b1c791-db89-4411-b194-abbd6cb9cf00"},{"cell_type":"markdown","source":"Let's delete the second level split on the ind1 == \"yes\" node:","metadata":{},"id":"0ea66323-03b3-4f12-b88f-a23457bd8337"},{"cell_type":"code","source":"counts_dt2b <- copy(counts_dt2)","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"49ab17cf-4e40-499d-9e86-d5be7b894ff4"},{"cell_type":"code","source":"counts_dt2b[ind1 == \"yes\", ind2 := NA]","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"1a5a4925-3acf-4a41-99ba-3e53e2552fc0"},{"cell_type":"code","source":"counts_dt2b <- counts_dt2b[, .(N = sum(N)), by = c(\"dep\", \"ind1\", \"ind2\")][, prop := N / sum(N), by = vars][]","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"ddcffae5-7e91-4981-8642-e6302326cd39"},{"cell_type":"code","source":"counts_dt2b","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"520e6ee5-629e-4c58-a460-afc642560e22"},{"cell_type":"markdown","source":"Calculate the entropy:","metadata":{},"id":"bee5407a-e423-48ff-b52c-e591d1c18120"},{"cell_type":"code","source":"ent2b <- counts_dt2b[, .(N = sum(N), ent = sum(-setdiff(prop, 0) * log2(setdiff(prop, 0)))), by = vars][, sum(N * ent) / sum(N)]\nent2b","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"7dcdb1ea-1fa0-4e32-aa8a-8e81ebcc20f2"},{"cell_type":"markdown","source":"Entropy is reduced by:","metadata":{},"id":"dc89971f-e95f-4c55-be2d-1a88de4a7252"},{"cell_type":"code","source":"ent1 - ent2b","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"2a5aa69c-4f36-4448-b514-ce5b9f3c8e75"},{"cell_type":"markdown","source":"So for short, **as long as the relative classification error decreases sufficiently**, at each node, next variable for split is chosen so that entropy is reduced most","metadata":{},"id":"bb7f8282-83dc-48c1-b901-e1276c6e2ef6"},{"cell_type":"markdown","source":"# rpart","metadata":{},"id":"5baef48d-ab55-463d-8c43-856c83d099b8"},{"cell_type":"markdown","source":"Now let's make rpart do the heavy lifting:","metadata":{},"id":"3385591a-8493-4e7f-94f5-17cd5ee7fcc1"},{"cell_type":"code","source":"churn.rp <- rpart::rpart(dep ~ ., data = vals_dt)","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"b2b5bdba-7f8a-4285-ae55-aab314579470"},{"cell_type":"markdown","source":"How the splits are done:","metadata":{},"id":"0a2621b2-32e6-4bda-8961-f676ce56b5d4"},{"cell_type":"code","source":"churn.rp","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"4ede0934-8ec3-4d6a-b866-7d33def9d465"},{"cell_type":"markdown","source":"Summary of complexity parameters (CP) table:","metadata":{},"id":"7e0f8dec-0bce-430c-9fb3-d5441a359ae9"},{"cell_type":"code","source":"printcp(churn.rp)","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"5449e085-f56f-4abb-8991-311c86535112"},{"cell_type":"markdown","source":"Remember the first value in the CP column: The decrease in relative error we calculated before.\n\nRelative error is the error at the depth level divided by the error at the root node (before any splits)","metadata":{},"id":"9baa4ece-fc01-4a1a-81d7-880b4df1957a"},{"cell_type":"markdown","source":"Let's extract the CP table","metadata":{},"id":"2f9f4c25-c51b-48ab-9a74-d5604eef37ab"},{"cell_type":"code","source":"cpdt <- churn.rp$cptable %>% as.data.table","metadata":{"trusted":true},"execution_count":null,"outputs":[],"id":"cf770544-6d40-4bac-95eb-d0a205a923ba"},{"cell_type":"code","source":"cpdt","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"b5aead36-0164-4da7-83b5-53999ea107d1"},{"cell_type":"markdown","source":"CP is the change in relative error if further splits are made, divided by the increase in number of splits:","metadata":{},"id":"96e8886d-fdf0-4476-95e8-8c9c0d789007"},{"cell_type":"code","source":"cpdt[, -diff(`rel error`) / diff(nsplit)]","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"7f49339d-d4e0-44a2-84af-085f95daa030"},{"cell_type":"markdown","source":"Let's visualize the tree:","metadata":{},"id":"87c609db-955b-416b-af20-aed38bfa55b8"},{"cell_type":"code","source":"visNetwork::visTree(churn.rp)","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[],"id":"5669eb34-2a39-407a-91f5-c61c8a985376"}]}